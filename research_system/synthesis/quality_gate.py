"""Quality gate for filtering LLM-generated strategy ideas.

Prevents AI slop by applying programmatic filters and ranking.
Hard cap: MAX_IDEAS = 3 ideas per synthesis run.
"""

from __future__ import annotations

import json
import logging
import re
from dataclasses import asdict, dataclass, field
from typing import Any, TYPE_CHECKING

logger = logging.getLogger(__name__)

# Hard cap on ideas per synthesis run
MAX_IDEAS = 3


# =============================================================================
# DATA CLASSES
# =============================================================================


@dataclass
class GeneratedIdea:
    """A strategy idea generated by a persona."""

    name: str
    thesis: str
    hypothesis: str
    entry_type: str  # "technical", "statistical", "event", "fundamental", "compound"
    data_requirements: list[str]  # Data source IDs needed
    entry_logic: str  # Specific entry conditions
    exit_logic: str  # Specific exit conditions
    risk_management: str  # Position sizing and risk rules
    expected_characteristics: dict[str, str]  # holding_period, trade_frequency, etc.
    confidence: str  # "high", "medium", "low"
    rationale: str  # Why this should work
    persona: str  # Which persona generated it
    related_strategies: list[str] = field(default_factory=list)  # Parent strategy IDs

    def to_dict(self) -> dict[str, Any]:
        """Serialize to dict."""
        return asdict(self)


@dataclass
class QualityResult:
    """Result of quality gate filtering."""

    accepted: list[GeneratedIdea]  # Passed quality gate (max 3)
    rejected: list[tuple[GeneratedIdea, str]]  # (idea, rejection_reason)
    total_generated: int


# =============================================================================
# QUALITY GATE
# =============================================================================


class QualityGate:
    """Two-phase quality filter for LLM-generated ideas.

    Phase 1: Programmatic filter -- rejects ideas that are missing required
    fields, have low confidence, or reference unavailable data.

    Phase 2: Ranking -- scores remaining ideas and caps at MAX_IDEAS.
    """

    def __init__(self, available_data: list[str] | None = None):
        self.available_data = set(available_data or [])

    def filter(self, ideas: list[GeneratedIdea]) -> QualityResult:
        """Two-phase filtering: programmatic then ranking."""
        # Phase 1: Programmatic filter
        passed = []
        rejected = []
        for idea in ideas:
            reason = self._check_programmatic(idea)
            if reason:
                rejected.append((idea, reason))
            else:
                passed.append(idea)

        # Phase 2: Rank and cap at MAX_IDEAS
        ranked = self._rank_ideas(passed)
        accepted = ranked[:MAX_IDEAS]
        for idea in ranked[MAX_IDEAS:]:
            rejected.append((idea, "Exceeded max ideas limit"))

        logger.info(
            "Quality gate: %d generated -> %d accepted, %d rejected",
            len(ideas),
            len(accepted),
            len(rejected),
        )

        return QualityResult(
            accepted=accepted,
            rejected=rejected,
            total_generated=len(ideas),
        )

    def _check_programmatic(self, idea: GeneratedIdea) -> str | None:
        """Return rejection reason or None if acceptable."""
        # Reject if missing entry logic
        if not idea.entry_logic or len(idea.entry_logic) < 20:
            return "Missing or too vague entry logic"

        # Reject if missing exit logic
        if not idea.exit_logic or len(idea.exit_logic) < 20:
            return "Missing or too vague exit logic"

        # Reject if missing hypothesis
        if not idea.hypothesis or len(idea.hypothesis) < 20:
            return "Missing or too vague hypothesis"

        # Reject if low confidence
        if idea.confidence == "low":
            return "Low confidence"

        # Check data requirements against available data (if we have registry)
        if self.available_data and idea.data_requirements:
            unavailable = [
                d
                for d in idea.data_requirements
                if d not in self.available_data and not self._is_standard_data(d)
            ]
            if unavailable:
                return f"References unavailable data: {', '.join(unavailable)}"

        return None

    def _is_standard_data(self, source: str) -> bool:
        """Check if it's standard QC data that doesn't need registry."""
        standard = {
            "equities",
            "futures",
            "options",
            "forex",
            "crypto",
            "us_equities",
            "spy",
            "qqq",
            "iwm",
            "vix",
            "tlt",
        }
        return source.lower().replace("-", "_") in standard

    def _rank_ideas(self, ideas: list[GeneratedIdea]) -> list[GeneratedIdea]:
        """Rank ideas by quality signals."""

        def score(idea: GeneratedIdea) -> int:
            s = 0
            if idea.confidence == "high":
                s += 3
            elif idea.confidence == "medium":
                s += 1
            if idea.related_strategies:
                s += 1  # Builds on existing work
            if len(idea.entry_logic) > 50:
                s += 1  # More specific
            if len(idea.exit_logic) > 50:
                s += 1
            return s

        return sorted(ideas, key=score, reverse=True)


# =============================================================================
# LLM RESPONSE PARSING
# =============================================================================


def parse_ideas_from_response(response: str, persona: str) -> list[GeneratedIdea]:
    """Parse GeneratedIdea list from LLM JSON response.

    Handles multiple response formats:
    - Raw JSON array
    - ```json fenced blocks
    - JSON object with an "ideas" key containing an array

    Never crashes on malformed responses -- returns an empty list on failure.

    Args:
        response: Raw text response from the LLM.
        persona: Persona name to attach to each idea.

    Returns:
        List of GeneratedIdea objects parsed from the response.
    """
    ideas: list[GeneratedIdea] = []

    # Try to extract JSON from the response
    json_str = _extract_json(response)
    if json_str is None:
        logger.warning("Could not extract JSON from persona %s response", persona)
        return ideas

    try:
        data = json.loads(json_str)
    except json.JSONDecodeError as exc:
        logger.warning(
            "Failed to parse JSON from persona %s: %s", persona, exc
        )
        return ideas

    # Normalise to a list of dicts
    if isinstance(data, dict):
        # Support {"ideas": [...]} wrapper
        if "ideas" in data and isinstance(data["ideas"], list):
            items = data["ideas"]
        else:
            items = [data]
    elif isinstance(data, list):
        items = data
    else:
        logger.warning("Unexpected JSON type from persona %s: %s", persona, type(data))
        return ideas

    for item in items:
        if not isinstance(item, dict):
            continue
        idea = _dict_to_idea(item, persona)
        if idea is not None:
            ideas.append(idea)

    logger.info("Parsed %d ideas from persona %s", len(ideas), persona)
    return ideas


def _extract_json(text: str) -> str | None:
    """Extract JSON string from LLM response text.

    Tries, in order:
    1. Fenced ```json ... ``` block
    2. First [ ... ] or { ... } span in the text
    3. The raw text itself

    Returns:
        Extracted JSON string, or None if nothing looks like JSON.
    """
    # Try fenced code block first
    match = re.search(r"```(?:json)?\s*\n?(.*?)```", text, re.DOTALL)
    if match:
        return match.group(1).strip()

    # Try to find raw JSON array or object
    for open_char, close_char in [("[", "]"), ("{", "}")]:
        start = text.find(open_char)
        if start == -1:
            continue
        # Find matching close -- walk from the end
        end = text.rfind(close_char)
        if end > start:
            return text[start : end + 1]

    # Last resort: maybe the whole thing is JSON
    stripped = text.strip()
    if stripped.startswith(("{", "[")):
        return stripped

    return None


def _dict_to_idea(d: dict[str, Any], persona: str) -> GeneratedIdea | None:
    """Convert a dict to a GeneratedIdea, filling in defaults for missing fields.

    Returns None if the dict is too incomplete to be useful.
    """
    try:
        return GeneratedIdea(
            name=str(d.get("name", "Unnamed Idea")),
            thesis=str(d.get("thesis", "")),
            hypothesis=str(d.get("hypothesis", "")),
            entry_type=str(d.get("entry_type", "technical")),
            data_requirements=_ensure_str_list(d.get("data_requirements", [])),
            entry_logic=str(d.get("entry_logic", "")),
            exit_logic=str(d.get("exit_logic", "")),
            risk_management=str(d.get("risk_management", "")),
            expected_characteristics=_ensure_str_dict(
                d.get("expected_characteristics", {})
            ),
            confidence=str(d.get("confidence", "medium")),
            rationale=str(d.get("rationale", "")),
            persona=persona,
            related_strategies=_ensure_str_list(d.get("related_strategies", [])),
        )
    except Exception as exc:  # noqa: BLE001
        logger.warning("Failed to convert dict to GeneratedIdea: %s", exc)
        return None


def _ensure_str_list(value: Any) -> list[str]:
    """Coerce *value* into a list of strings."""
    if isinstance(value, list):
        return [str(v) for v in value]
    if isinstance(value, str):
        return [value]
    return []


def _ensure_str_dict(value: Any) -> dict[str, str]:
    """Coerce *value* into a dict of str -> str."""
    if isinstance(value, dict):
        return {str(k): str(v) for k, v in value.items()}
    return {}
